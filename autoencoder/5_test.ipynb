{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e1_Y75QXJS6h"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-22T07:21:45.697333Z",
     "iopub.status.busy": "2024-05-22T07:21:45.697108Z",
     "iopub.status.idle": "2024-05-22T07:21:49.108941Z",
     "shell.execute_reply": "2024-05-22T07:21:49.107726Z"
    },
    "id": "YfIk2es3hJEd"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "image_folder = \"4.1/images\"\n",
    "weights_folder = \"4.1/weights\"\n",
    "test_folder = \"148color.test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iYn4MdZnKCey"
   },
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-22T07:21:49.123932Z",
     "iopub.status.busy": "2024-05-22T07:21:49.123476Z",
     "iopub.status.idle": "2024-05-22T07:21:49.137475Z",
     "shell.execute_reply": "2024-05-22T07:21:49.136629Z"
    }
   },
   "outputs": [],
   "source": [
    "class ImagePairDataGenerator(tf.keras.utils.PyDataset):\n",
    "\n",
    "    def __init__(self, input_files, output_files, batch_size, img_shape):\n",
    "        self.input_files = input_files\n",
    "        self.output_files = output_files\n",
    "        self.batch_size = batch_size\n",
    "        self.img_shape = img_shape\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_files) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_input_files = self.input_files[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch_output_files = self.output_files[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        X, y = self.__data_generation(batch_input_files, batch_output_files)\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indices = np.arange(len(self.input_files))\n",
    "        np.random.shuffle(self.indices)\n",
    "        self.input_files = [self.input_files[i] for i in self.indices]\n",
    "        self.output_files = [self.output_files[i] for i in self.indices]\n",
    "\n",
    "    def __data_generation(self, batch_input_files, batch_output_files):\n",
    "        X = np.empty((self.batch_size, *self.img_shape), dtype=np.float32)\n",
    "        y = np.empty((self.batch_size, *self.img_shape), dtype=np.float32)\n",
    "\n",
    "        for i, (input_path, output_path) in enumerate(zip(batch_input_files, batch_output_files)):\n",
    "\n",
    "            input_image = ImagePairDataGenerator.load_and_pp_image(input_path)\n",
    "            output_image = ImagePairDataGenerator.load_and_pp_image(output_path)\n",
    "\n",
    "            X[i,] = input_image\n",
    "            y[i,] = output_image\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    @staticmethod\n",
    "    def load_and_pp_image(img_path: str):\n",
    "        img = Image.open(img_path)\n",
    "        img = np.array(img) / 255.0\n",
    "        img = img.reshape(148, 148, 3).astype('float32')\n",
    "        return img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-22T07:21:50.352279Z",
     "iopub.status.busy": "2024-05-22T07:21:50.351938Z",
     "iopub.status.idle": "2024-05-22T07:21:50.377697Z",
     "shell.execute_reply": "2024-05-22T07:21:50.376791Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Input, Conv2D, UpSampling2D, BatchNormalization\n",
    "\n",
    "\n",
    "class AEModel(Model):\n",
    "        \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "        self.mae_metric = keras.metrics.MeanAbsoluteError(name=\"mae\")\n",
    "        self.optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self, x):\n",
    "        images, waters = x\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(waters, training=True)\n",
    "            loss = keras.losses.mse(images, y_pred)\n",
    "\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "\n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "\n",
    "        # Compute our own metrics\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        self.mae_metric.update_state(images, y_pred)\n",
    "        return {\"loss\": self.loss_tracker.result(), \"mae\": self.mae_metric.result()}\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.loss_tracker, self.mae_metric]\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_model():\n",
    "        x = Input(shape=(148, 148, 3))\n",
    "\n",
    "        e_conv1 = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "        pool1 = MaxPooling2D((2, 2), padding='same')(e_conv1)\n",
    "        batchnorm_1 = BatchNormalization()(pool1)\n",
    "\n",
    "        e_conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(batchnorm_1)\n",
    "        pool2 = MaxPooling2D((2, 2), padding='same')(e_conv2)\n",
    "        batchnorm_2 = BatchNormalization()(pool2)\n",
    "\n",
    "        e_conv3 = Conv2D(32, (3, 3), activation='relu', padding='same')(batchnorm_2)\n",
    "        h = MaxPooling2D((2, 2), padding='same')(e_conv3)\n",
    "\n",
    "        d_conv1 = Conv2D(128, (3, 3), activation='relu', padding='same')(h)\n",
    "        up1 = UpSampling2D((2, 2))(d_conv1)\n",
    "\n",
    "        d_conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(up1)\n",
    "        up2 = UpSampling2D((2, 2))(d_conv2)\n",
    "\n",
    "        d_conv3 = Conv2D(32, (3, 3), activation='relu')(up2)\n",
    "        up3 = UpSampling2D((2, 2))(d_conv3)\n",
    "\n",
    "        r = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(up3)\n",
    "\n",
    "        return x, r\n",
    "\n",
    "filepath = os.path.join(weights_folder, \"final.keras\")\n",
    "\n",
    "model = tf.keras.models.load_model(filepath, custom_objects={'AEModel': AEModel})\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rw1fkAczTQYh"
   },
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icecream import ic\n",
    "\n",
    "\n",
    "files = os.listdir(test_folder)\n",
    "files.sort()\n",
    "\n",
    "ic(\"Number of files:\", len(files))\n",
    "\n",
    "test_images = []\n",
    "test_waters = []\n",
    "for i in range(0, len(files), 2):\n",
    "    test_images.append(os.path.join(test_folder, files[i]))\n",
    "    test_waters.append(os.path.join(test_folder, files[i+1]))\n",
    "\n",
    "for test_image, test_water in zip(test_images[:5], test_waters[:5]):\n",
    "    ic(test_image, test_water)\n",
    "\n",
    "image_shape = ImagePairDataGenerator.load_and_pp_image(test_images[0]).shape\n",
    "test_generator = ImagePairDataGenerator(test_images, test_waters, 1, image_shape)\n",
    "\n",
    "print(\"Size of test generator\", len(test_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-22T07:21:50.384212Z",
     "iopub.status.busy": "2024-05-22T07:21:50.383836Z",
     "iopub.status.idle": "2024-05-22T07:21:51.419582Z",
     "shell.execute_reply": "2024-05-22T07:21:51.418639Z"
    },
    "id": "RmdVsmvhPxyy"
   },
   "outputs": [],
   "source": [
    "images_to_try = 40\n",
    "\n",
    "plt.close('all')\n",
    "\n",
    "fig, ax = plt.subplots(images_to_try, 2, figsize=(8,50))\n",
    "for i in range(images_to_try):\n",
    "    test_image, test_water = test_generator.__getitem__(i)\n",
    "\n",
    "    prediction = model(test_water, training=False)\n",
    "    test_image = np.squeeze (test_image)\n",
    "    test_water = np.squeeze(test_water)\n",
    "    prediction = np.squeeze(prediction)\n",
    "\n",
    "    ax[i][0].imshow(test_water)\n",
    "    ax[i][1].imshow(prediction)\n",
    "    ax[i][0].axis('off')\n",
    "    ax[i][1].axis('off')\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cvae.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
