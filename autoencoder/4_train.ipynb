{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e1_Y75QXJS6h"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-22T07:21:45.697333Z",
     "iopub.status.busy": "2024-05-22T07:21:45.697108Z",
     "iopub.status.idle": "2024-05-22T07:21:49.108941Z",
     "shell.execute_reply": "2024-05-22T07:21:49.107726Z"
    },
    "id": "YfIk2es3hJEd"
   },
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "image_folder = \"4.1/images\"\n",
    "weights_folder = \"4.1/weights\"\n",
    "\n",
    "train_folder = \"148color.train\"\n",
    "anim_file = \"4.1.training.gif\"\n",
    "\n",
    "epochs = 500\n",
    "save_every_n_epoch = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-22T07:21:49.114642Z",
     "iopub.status.busy": "2024-05-22T07:21:49.114192Z",
     "iopub.status.idle": "2024-05-22T07:21:49.118942Z",
     "shell.execute_reply": "2024-05-22T07:21:49.118086Z"
    }
   },
   "outputs": [],
   "source": [
    "Path(image_folder).mkdir(exist_ok=True, parents=True)\n",
    "Path(weights_folder).mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iYn4MdZnKCey"
   },
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-22T07:21:49.123932Z",
     "iopub.status.busy": "2024-05-22T07:21:49.123476Z",
     "iopub.status.idle": "2024-05-22T07:21:49.137475Z",
     "shell.execute_reply": "2024-05-22T07:21:49.136629Z"
    }
   },
   "outputs": [],
   "source": [
    "files = os.listdir(train_folder)\n",
    "files.sort()\n",
    "\n",
    "print(\"Number of files:\", len(files))\n",
    "\n",
    "file_pairs = []\n",
    "for i in range(0, len(files), 2):\n",
    "    file_pairs.append((os.path.join(train_folder, files[i]), os.path.join(train_folder, files[i+1])))\n",
    "\n",
    "\n",
    "# ######\n",
    "# Get image data and demo normalization\n",
    "# ######\n",
    "\n",
    "\n",
    "train_pairs, validation_pairs = train_test_split(file_pairs, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Train pairs:\", len(train_pairs))\n",
    "print(\"Validation pairs:\", len(validation_pairs))\n",
    "\n",
    "# ######\n",
    "# x - images\n",
    "# y - watermarked images\n",
    "\n",
    "train_images = []\n",
    "train_waters = []\n",
    "val_images = []\n",
    "val_waters = []\n",
    "\n",
    "for image_path, watermarked_image_path in train_pairs:\n",
    "    train_images.append(image_path)\n",
    "    train_waters.append(watermarked_image_path)\n",
    "\n",
    "for image_path, watermarked_image_path in validation_pairs:\n",
    "    val_images.append(image_path)\n",
    "    val_waters.append(watermarked_image_path)\n",
    "\n",
    "# ######\n",
    "# generator\n",
    "\n",
    "class ImagePairDataGenerator(tf.keras.utils.PyDataset):\n",
    "\n",
    "    def __init__(self, input_files, output_files, batch_size, img_shape):\n",
    "        self.input_files = input_files\n",
    "        self.output_files = output_files\n",
    "        self.batch_size = batch_size\n",
    "        self.img_shape = img_shape\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_files) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_input_files = self.input_files[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch_output_files = self.output_files[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        X, y = self.__data_generation(batch_input_files, batch_output_files)\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indices = np.arange(len(self.input_files))\n",
    "        np.random.shuffle(self.indices)\n",
    "        self.input_files = [self.input_files[i] for i in self.indices]\n",
    "        self.output_files = [self.output_files[i] for i in self.indices]\n",
    "\n",
    "    def __data_generation(self, batch_input_files, batch_output_files):\n",
    "        X = np.empty((self.batch_size, *self.img_shape), dtype=np.float32)\n",
    "        y = np.empty((self.batch_size, *self.img_shape), dtype=np.float32)\n",
    "\n",
    "        for i, (input_path, output_path) in enumerate(zip(batch_input_files, batch_output_files)):\n",
    "\n",
    "            input_image = ImagePairDataGenerator.load_and_pp_image(input_path)\n",
    "            output_image = ImagePairDataGenerator.load_and_pp_image(output_path)\n",
    "\n",
    "            X[i,] = input_image\n",
    "            y[i,] = output_image\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    @staticmethod\n",
    "    def load_and_pp_image(img_path: str):\n",
    "        img = Image.open(img_path)\n",
    "        img = np.array(img) / 255.0\n",
    "        img = img.reshape(148, 148, 3).astype('float32')\n",
    "        return img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-22T07:21:49.141965Z",
     "iopub.status.busy": "2024-05-22T07:21:49.141269Z",
     "iopub.status.idle": "2024-05-22T07:21:49.156336Z",
     "shell.execute_reply": "2024-05-22T07:21:49.155487Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "image_shape = ImagePairDataGenerator.load_and_pp_image(file_pairs[0][0]).shape\n",
    "\n",
    "train_generator = ImagePairDataGenerator(train_images, train_waters, batch_size, image_shape)\n",
    "val_generator = ImagePairDataGenerator(val_images, val_waters, batch_size, image_shape)\n",
    "\n",
    "num_examples_to_generate = 4\n",
    "\n",
    "\n",
    "def generate_and_save_images(model, epoch, test_sample):\n",
    "    predictions = model(test_sample, training=False)\n",
    "    \n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4, 4, i + 1)\n",
    "        plt.imshow(predictions[i, :, :, 0])\n",
    "        plt.axis('off')\n",
    "\n",
    "    # tight_layout minimizes the overlap between 2 sub-plots\n",
    "    plt.savefig(f'{image_folder}/image_at_epoch_{epoch:04d}.png')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Pick a sample of the test set for generating output images\n",
    "assert batch_size >= num_examples_to_generate\n",
    "\n",
    "plt.close('all')\n",
    "\n",
    "test_batch_imgs, test_batch_waters = val_generator.__getitem__(0)\n",
    "test_sample = test_batch_waters[0:num_examples_to_generate]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "THY-sZMiQ4UV"
   },
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-22T07:21:49.160780Z",
     "iopub.status.busy": "2024-05-22T07:21:49.160484Z",
     "iopub.status.idle": "2024-05-22T07:21:50.347436Z",
     "shell.execute_reply": "2024-05-22T07:21:50.346150Z"
    },
    "id": "VGLbvBEmjK0a"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Input, Conv2D, UpSampling2D, BatchNormalization\n",
    "\n",
    "\n",
    "class AEModel(Model):\n",
    "        \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "        self.mae_metric = keras.metrics.MeanAbsoluteError(name=\"mae\")\n",
    "        self.optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self, x):\n",
    "        images, waters = x\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(waters, training=True)\n",
    "            loss = keras.losses.mse(images, y_pred)\n",
    "\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "\n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "\n",
    "        # Compute our own metrics\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        self.mae_metric.update_state(images, y_pred)\n",
    "        return {\"loss\": self.loss_tracker.result(), \"mae\": self.mae_metric.result()}\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.loss_tracker, self.mae_metric]\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_model():\n",
    "        x = Input(shape=(148, 148, 3))\n",
    "\n",
    "        e_conv1 = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "        pool1 = MaxPooling2D((2, 2), padding='same')(e_conv1)\n",
    "        batchnorm_1 = BatchNormalization()(pool1)\n",
    "\n",
    "        e_conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(batchnorm_1)\n",
    "        pool2 = MaxPooling2D((2, 2), padding='same')(e_conv2)\n",
    "        batchnorm_2 = BatchNormalization()(pool2)\n",
    "\n",
    "        e_conv3 = Conv2D(32, (3, 3), activation='relu', padding='same')(batchnorm_2)\n",
    "        h = MaxPooling2D((2, 2), padding='same')(e_conv3)\n",
    "\n",
    "        d_conv1 = Conv2D(128, (3, 3), activation='relu', padding='same')(h)\n",
    "        up1 = UpSampling2D((2, 2))(d_conv1)\n",
    "\n",
    "        d_conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(up1)\n",
    "        up2 = UpSampling2D((2, 2))(d_conv2)\n",
    "\n",
    "        d_conv3 = Conv2D(32, (3, 3), activation='relu')(up2)\n",
    "        up3 = UpSampling2D((2, 2))(d_conv3)\n",
    "\n",
    "        r = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(up3)\n",
    "\n",
    "        return x, r\n",
    "\n",
    "x, r = AEModel.get_model()\n",
    "\n",
    "model = AEModel(x, r)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rw1fkAczTQYh"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-22T07:21:50.384212Z",
     "iopub.status.busy": "2024-05-22T07:21:50.383836Z",
     "iopub.status.idle": "2024-05-22T07:21:51.419582Z",
     "shell.execute_reply": "2024-05-22T07:21:51.418639Z"
    },
    "id": "RmdVsmvhPxyy"
   },
   "outputs": [],
   "source": [
    "generate_and_save_images(model, 0, test_sample)\n",
    "\n",
    "fig = plt.figure(figsize=(4, 4))\n",
    "for i in range(test_sample.shape[0]):\n",
    "    plt.subplot(4, 4, i + 1)\n",
    "    img = test_sample[i, :, :, 0]\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-22T07:21:51.422062Z",
     "iopub.status.busy": "2024-05-22T07:21:51.421873Z",
     "iopub.status.idle": "2024-05-22T07:26:13.058941Z",
     "shell.execute_reply": "2024-05-22T07:26:13.058077Z"
    }
   },
   "outputs": [],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    start_time = time.time()\n",
    "    for batch in range(len(train_generator)):\n",
    "        train_x = train_generator.__getitem__(batch)\n",
    "        history = model.train_step(train_x)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    display.clear_output(wait=False)\n",
    "    \n",
    "    print('Epoch: {}, MAE: {}, Time: {}'.format(epoch, history['mae'], end_time - start_time))\n",
    "    \n",
    "    generate_and_save_images(model, epoch, test_sample)\n",
    "    if epoch % save_every_n_epoch == 0:\n",
    "        model.save(f'{weights_folder}/epoch_{epoch:03d}.keras')\n",
    "\n",
    "model.save(f'{weights_folder}/final.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P4M_vIbUi7c0"
   },
   "source": [
    "### Display a generated image from the last training epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-22T07:26:13.062496Z",
     "iopub.status.busy": "2024-05-22T07:26:13.062299Z",
     "iopub.status.idle": "2024-05-22T07:26:13.065451Z",
     "shell.execute_reply": "2024-05-22T07:26:13.064946Z"
    },
    "id": "WfO5wCdclHGL"
   },
   "outputs": [],
   "source": [
    "def display_image(epoch_no):\n",
    "  return PIL.Image.open(f'{image_folder}/image_at_epoch_{epoch_no:04d}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-22T07:26:13.067884Z",
     "iopub.status.busy": "2024-05-22T07:26:13.067705Z",
     "iopub.status.idle": "2024-05-22T07:26:13.185108Z",
     "shell.execute_reply": "2024-05-22T07:26:13.184430Z"
    },
    "id": "5x3q9_Oe5q0A"
   },
   "outputs": [],
   "source": [
    "plt.imshow(display_image(epoch))\n",
    "plt.axis('off')  # Display images\n",
    "\n",
    "fig = plt.figure(figsize=(4, 4))\n",
    "for i in range(test_sample.shape[0]):\n",
    "    plt.subplot(4, 4, i + 1)\n",
    "    img = test_sample[i, :, :, 0]\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NywiH3nL8guF"
   },
   "source": [
    "### Display an animated GIF of all the saved images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-22T07:26:13.187820Z",
     "iopub.status.busy": "2024-05-22T07:26:13.187628Z",
     "iopub.status.idle": "2024-05-22T07:26:17.764168Z",
     "shell.execute_reply": "2024-05-22T07:26:17.763313Z"
    },
    "id": "IGKQgENQ8lEI"
   },
   "outputs": [],
   "source": [
    "with imageio.get_writer(anim_file, mode='I') as writer:\n",
    "    filenames = glob.glob(f'{image_folder}/*.png')\n",
    "    filenames = sorted(filenames)\n",
    "    for filename in filenames:\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)\n",
    "    image = imageio.imread(filename)\n",
    "    writer.append_data(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-22T07:26:17.768929Z",
     "iopub.status.busy": "2024-05-22T07:26:17.768733Z",
     "iopub.status.idle": "2024-05-22T07:26:17.811186Z",
     "shell.execute_reply": "2024-05-22T07:26:17.810432Z"
    },
    "id": "2ZqAEtdqUmJF"
   },
   "outputs": [],
   "source": [
    "import tensorflow_docs.vis.embed as embed\n",
    "\n",
    "embed.embed_file(anim_file)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cvae.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
